{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression linéaire et logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder une fonction `linear_regression(theta, x)` qui retoure $y = \\sum_{i=0}^n \\theta_i x_i$. On prendra $x_0 = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def linear_regression(theta, x): #~proto de la fonction\n",
    "    sum_linear_regression = 0\n",
    "    for (theta_i, x_j) in zip(theta, x):\n",
    "            sum_linear_regression = sum_linear_regression + (theta_i * x_j)\n",
    "    return sum_linear_regression\n",
    "# linear_regression([2, 2, 2], [1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder la fonction `linear_regression_cost(model, X, Y)` qui prend argument un modèle, un ensemble d'exemple et de labels et qui calcule son erreur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_regression_cost(theta, X, Y):\n",
    "    partial_linear_regression_cost = 0\n",
    "    for (theta_i, X_j, Y_k) in zip(theta, X, Y):\n",
    "            partial_linear_regression_cost = (1/(2*len(theta)))*(linear_regression(theta, X_j) - Y_k) ** 2\n",
    "    return partial_linear_regression_cost\n",
    "# linear_regression_cost(np.array([1, 2]), np.array([[1, 2], [1, 3]]), np.array([3, 8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On note $J(\\theta)$ la fonction de coût de du modèle (qui mesure sa performance sur l'ensemble de train). Calculer $\\frac{\\partial J}{\\partial \\theta_i} $. Coder la fonction `get_cost_derivative(model, X, Y)` qui retourne les dérivée partielles de la fonction de coût"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost_derivative(theta, X, Y): # Pour la fonction  linear_regression_cost(model, X, Y),  remplacez 'model', par 'theta'\n",
    "    # linear_regression_cost(theta, X, Y) = 1/2 poop\n",
    "    theta0_get_cost_derivative = 0\n",
    "    theta1_get_cost_derivative = 0\n",
    "    for (theta_i, X_j, Y_k) in zip(theta, X, Y):\n",
    "        theta0_get_cost_derivative = (theta0 + theta1 * X - Y) / len(theta0)\n",
    "        theta1_get_cost_derivative = (theta0 + theta1 * X - Y) * X / len(theta1)\n",
    "        get_cost_derivative = theta0_get_cost_derivative + theta1_get_cost_derivative\n",
    "    return get_cost_derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder une fonction `gradient_descent(initial_model, X, Y, max_iteration)` qui effectue la descente de gradient pour la régression linéaire. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"\"\" #equivalent descente gradient par le taux de variation d'une fonction à un point donné#\n",
    "    def variation_rate(f, x, h):\n",
    "    return (f(x+h)-f(x))/h\n",
    "    \n",
    "    def lower_point(f, x, h):\n",
    "        xprime = x\n",
    "        cpt=0\n",
    "        while(cpt<100):\n",
    "            cpt+=1\n",
    "            if (variation_rate(f, xprime, h) < 0):\n",
    "                xprime = xprime+h\n",
    "                print(\"x:\", xprime)\n",
    "            elif (variation_rate(f, xprime, h) > 0):\n",
    "                xprime = xprime-h\n",
    "                print(\"x:\", xprime)\n",
    "            else:\n",
    "                break\"\"\"\n",
    "        \n",
    "        def gradient_descent(initial_theta, X, Y): #pour la descente de gradient remplacez \"initial_model\" par \"initial_theta\"\n",
    "    \n",
    "    for i in range(max_iteration):\n",
    "        # use previous functions!\n",
    "        theta = initial_theta\n",
    "        cpt=0\n",
    "        while(cpt<10):\n",
    "            cpt+=1\n",
    "            if (get_cost_derivative(theta, X, Y) < 0):\n",
    "        temp0 := theta0 - alpha * theta0_get_cost_derivative\n",
    "        temp1 := theta1 - alpha * theta1_get_cost_derivative\n",
    "        theta0 := temp0\n",
    "        theta1 := temp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Génerer un jeux de donnée simple et tester votre approche. Vous pourrez afficher le sur un graphique les données initiale et les prédictions de votre modèle après l'inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder la fonction `sigmoid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder la fonction `logistic_regression_cost(model, X, Y)`. On (ra)pelle que la fonction de coût pour la régression logistique est différente de la fonction de coût de la régression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coder la fonction `gradient_descent(initial_model, X, Y)` qui effectue la descente de gradient pour la régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
